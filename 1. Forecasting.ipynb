{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "1. Forecasting.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FggQv5PvSm5L"
      },
      "source": [
        "<h1><font color=\"#113D68\" size=6>Deep Learning con Python con Python y Keras</font></h1>\n",
        "\n",
        "<h1><font color=\"#113D68\" size=5>Parte 4. MLP avanzado</font></h1>\n",
        "\n",
        "<h1><font color=\"#113D68\" size=4>1. Forecasting</font></h1>\n",
        "\n",
        "<br><br>\n",
        "<div style=\"text-align: right\">\n",
        "<font color=\"#113D68\" size=3>Manuel Castillo Cara</font><br>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtm4AhR7Sm5M"
      },
      "source": [
        "---\n",
        "\n",
        "<a id=\"indice\"></a>\n",
        "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
        "\n",
        "* [0. Contexto](#section0)\n",
        "* [1. Introducción](#section1)\n",
        "    * [1.1. Formato HDF5](#section1.1)\n",
        "* [2. Guardar el modelo en JSON](#section2)\n",
        "* [3. Guardar el modelo en YAML](#section3)\n",
        "* [4. Guardar topología y pesos](#section4)\n",
        "    * [4.1. Guardar el modelo](#section4.1)\n",
        "    * [4.2. Cargar el modelo](#section4.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMT3FbP2Sm5N"
      },
      "source": [
        "---\n",
        "<a id=\"section0\"></a>\n",
        "# <font color=\"#004D7F\" size=6> 0. Contexto</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYxFldovSm5N"
      },
      "source": [
        "En esta lección, descubrirá cómo puede guardar nuestros modelos en un archivo y volver a cargarlos para hacer predicciones. Después de completar esta lección, sabrá:\n",
        "* Cómo guardar y cargar los pesos del modelo en archivos formateados HDF5.\n",
        "* Cómo guardar y cargar la estructura del modelo en archivos JSON.\n",
        "* Cómo guardar y cargar la estructura del modelo en archivos YAML."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gGimvkSm5O"
      },
      "source": [
        "import tensorflow as tf\n",
        "# Eliminar warning\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9omZy3mSm5O"
      },
      "source": [
        "---\n",
        "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX8ANCqMSm5P"
      },
      "source": [
        "<a id=\"section1\"></a>\n",
        "# <font color=\"#004D7F\" size=6>1. Introducción</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVIe_xS7Sm5P"
      },
      "source": [
        "Keras puede guardar la arquitectura de su modelo y guardar los pesos y nuestro modelo. \n",
        "1. Los pesos de los modelos se guardan en formato HDF5. \n",
        "2. El modelo se puede guardar (y cargar) utilizando dos formatos diferentes: JSON y YAML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZMmBXTLSm5Q"
      },
      "source": [
        "<a id=\"section1.1\"></a>\n",
        "# <font color=\"#004D7F\" size=5>1.1. Formato HDF5</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyJ1KD_GSm5Q"
      },
      "source": [
        "El formato de datos jerárquico (HDF5) es un formato de almacenamiento de datos flexible y es conveniente para almacenar grandes conjuntos de valores reales, como tenemos en los pesos de las redes neuronales. Puede instalar este formato con `pip`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmp9k61TSm5Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "660d249e-bcf4-4bbd-c2b1-134561399bca"
      },
      "source": [
        "#!pip install h5py\n",
        "!pip install h5py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo0tke19Sm5R"
      },
      "source": [
        "---\n",
        "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1H2dN_RSm5R"
      },
      "source": [
        "<a id=\"section2\"></a>\n",
        "# <font color=\"#004D7F\" size=6>2. Guardar el modelo en JSON</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ-if3ppSm5R"
      },
      "source": [
        "Keras brinda la capacidad de describir cualquier modelo usando formato JSON con una función `to_json()`. Posteriormente, podemos cargarlo a través de `model_from_json()`.\n",
        "\n",
        "Los pesos se guardan directamente usando la función `save_weights()` y luego se cargan usando la función `load_weights()`. \n",
        "\n",
        "El siguiente ejemplo entrena y evalúa un modelo. Luego, la estructura del modelo se convierte a formato JSON con `model.json` en el directorio local. Los pesos de la red se escriben en `model.h5`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmhtpYmrSm5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015125c2-e339-43d0-b627-8a6acd214c2e"
      },
      "source": [
        "# MLP for Pima Indians Dataset Serialize to JSON and HDF5\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import model_from_json\n",
        "import numpy as np\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = np.loadtxt(\"https://raw.githubusercontent.com/FMunyoz/colab/main/Datasets/pima-indians-diabetes.csv\", delimiter=',')\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:, 0:8]\n",
        "y = dataset[:, 8]\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Modelo guardado\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 75.91%\n",
            "Modelo guardado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DOkMZq9TSm5T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dbc47e0-4f2f-461f-d61d-d7b132ac82d7"
      },
      "source": [
        "# load json and create model\n",
        "json_file = open('model.json','r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "# evaluate loaded model on test data\n",
        "scores = model.evaluate(X, y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 75.91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkXF6NK2Sm5T"
      },
      "source": [
        "El formato JSON del modelo tiene el siguiente aspecto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vsYxyzBQSm5T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d50fed12-1419-494f-a79b-7ad3b5a8e246"
      },
      "source": [
        "cat model.json | python -mjson.tool"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"class_name\": \"Sequential\",\n",
            "    \"config\": {\n",
            "        \"name\": \"sequential_2\",\n",
            "        \"layers\": [\n",
            "            {\n",
            "                \"class_name\": \"InputLayer\",\n",
            "                \"config\": {\n",
            "                    \"batch_input_shape\": [\n",
            "                        null,\n",
            "                        8\n",
            "                    ],\n",
            "                    \"dtype\": \"float32\",\n",
            "                    \"sparse\": false,\n",
            "                    \"ragged\": false,\n",
            "                    \"name\": \"dense_6_input\"\n",
            "                }\n",
            "            },\n",
            "            {\n",
            "                \"class_name\": \"Dense\",\n",
            "                \"config\": {\n",
            "                    \"name\": \"dense_6\",\n",
            "                    \"trainable\": true,\n",
            "                    \"batch_input_shape\": [\n",
            "                        null,\n",
            "                        8\n",
            "                    ],\n",
            "                    \"dtype\": \"float32\",\n",
            "                    \"units\": 12,\n",
            "                    \"activation\": \"relu\",\n",
            "                    \"use_bias\": true,\n",
            "                    \"kernel_initializer\": {\n",
            "                        \"class_name\": \"GlorotUniform\",\n",
            "                        \"config\": {\n",
            "                            \"seed\": null\n",
            "                        }\n",
            "                    },\n",
            "                    \"bias_initializer\": {\n",
            "                        \"class_name\": \"Zeros\",\n",
            "                        \"config\": {}\n",
            "                    },\n",
            "                    \"kernel_regularizer\": null,\n",
            "                    \"bias_regularizer\": null,\n",
            "                    \"activity_regularizer\": null,\n",
            "                    \"kernel_constraint\": null,\n",
            "                    \"bias_constraint\": null\n",
            "                }\n",
            "            },\n",
            "            {\n",
            "                \"class_name\": \"Dense\",\n",
            "                \"config\": {\n",
            "                    \"name\": \"dense_7\",\n",
            "                    \"trainable\": true,\n",
            "                    \"dtype\": \"float32\",\n",
            "                    \"units\": 8,\n",
            "                    \"activation\": \"relu\",\n",
            "                    \"use_bias\": true,\n",
            "                    \"kernel_initializer\": {\n",
            "                        \"class_name\": \"GlorotUniform\",\n",
            "                        \"config\": {\n",
            "                            \"seed\": null\n",
            "                        }\n",
            "                    },\n",
            "                    \"bias_initializer\": {\n",
            "                        \"class_name\": \"Zeros\",\n",
            "                        \"config\": {}\n",
            "                    },\n",
            "                    \"kernel_regularizer\": null,\n",
            "                    \"bias_regularizer\": null,\n",
            "                    \"activity_regularizer\": null,\n",
            "                    \"kernel_constraint\": null,\n",
            "                    \"bias_constraint\": null\n",
            "                }\n",
            "            },\n",
            "            {\n",
            "                \"class_name\": \"Dense\",\n",
            "                \"config\": {\n",
            "                    \"name\": \"dense_8\",\n",
            "                    \"trainable\": true,\n",
            "                    \"dtype\": \"float32\",\n",
            "                    \"units\": 1,\n",
            "                    \"activation\": \"sigmoid\",\n",
            "                    \"use_bias\": true,\n",
            "                    \"kernel_initializer\": {\n",
            "                        \"class_name\": \"GlorotUniform\",\n",
            "                        \"config\": {\n",
            "                            \"seed\": null\n",
            "                        }\n",
            "                    },\n",
            "                    \"bias_initializer\": {\n",
            "                        \"class_name\": \"Zeros\",\n",
            "                        \"config\": {}\n",
            "                    },\n",
            "                    \"kernel_regularizer\": null,\n",
            "                    \"bias_regularizer\": null,\n",
            "                    \"activity_regularizer\": null,\n",
            "                    \"kernel_constraint\": null,\n",
            "                    \"bias_constraint\": null\n",
            "                }\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    \"keras_version\": \"2.5.0\",\n",
            "    \"backend\": \"tensorflow\"\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTStoyaxSm5T"
      },
      "source": [
        "---\n",
        "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBm8bXpKSm5T"
      },
      "source": [
        "<a id=\"section3\"></a>\n",
        "# <font color=\"#004D7F\" size=6>3. Guardar el modelo en YAML</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSdPtfxZSm5U"
      },
      "source": [
        "El modelo se guarda como YAML en el archivo `model.yaml` y luego se carga en un nuevo modelo a través de la función `model_from_yaml()`. \n",
        "\n",
        "Los pesos se manejan de la misma manera en formato HDF5, `model.h5`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbe0o10iSm5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82c86e1c-d572-46f6-91a4-3c3d25272c42"
      },
      "source": [
        "# MLP for Pima Indians Dataset Serialize to YAML and HDF5\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import model_from_yaml\n",
        "import numpy as np\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = np.loadtxt(\"https://raw.githubusercontent.com/FMunyoz/colab/main/Datasets/pima-indians-diabetes.csv\", delimiter=',')\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:, 0:8]\n",
        "y = dataset[:, 8]\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# serialize model to JSON\n",
        "model_yaml = model.to_yaml()\n",
        "with open(\"model.yaml\", \"w\") as yaml_file:\n",
        "  yaml_file.write(model_yaml)\n",
        "\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Modelo guardado\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 75.91%\n",
            "Modelo guardado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zZd4U_JSm5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5194b834-d454-4dac-a333-437b15cfe1c8"
      },
      "source": [
        "# load yaml and create model\n",
        "yaml_file = open('model.yaml','r')\n",
        "loaded_model_yaml = yaml_file.read()\n",
        "yaml_file.close()\n",
        "loaded_model = model_from_yaml(loaded_model_yaml)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "# evaluate loaded model on test data\n",
        "scores = model.evaluate(X, y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 75.91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-64PKM2Sm5U"
      },
      "source": [
        "El modelo descrito en formato YAML tiene el siguiente aspecto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dr1tMRYGSm5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6a5c5d-229c-4b36-ff41-1de1958dab47"
      },
      "source": [
        "print(loaded_model_yaml)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "backend: tensorflow\n",
            "class_name: Sequential\n",
            "config:\n",
            "  layers:\n",
            "  - class_name: InputLayer\n",
            "    config:\n",
            "      batch_input_shape: !!python/tuple [null, 8]\n",
            "      dtype: float32\n",
            "      name: dense_input\n",
            "      ragged: false\n",
            "      sparse: false\n",
            "  - class_name: Dense\n",
            "    config:\n",
            "      activation: relu\n",
            "      activity_regularizer: null\n",
            "      batch_input_shape: !!python/tuple [null, 8]\n",
            "      bias_constraint: null\n",
            "      bias_initializer:\n",
            "        class_name: Zeros\n",
            "        config: {}\n",
            "      bias_regularizer: null\n",
            "      dtype: float32\n",
            "      kernel_constraint: null\n",
            "      kernel_initializer:\n",
            "        class_name: GlorotUniform\n",
            "        config: {seed: null}\n",
            "      kernel_regularizer: null\n",
            "      name: dense\n",
            "      trainable: true\n",
            "      units: 12\n",
            "      use_bias: true\n",
            "  - class_name: Dense\n",
            "    config:\n",
            "      activation: relu\n",
            "      activity_regularizer: null\n",
            "      bias_constraint: null\n",
            "      bias_initializer:\n",
            "        class_name: Zeros\n",
            "        config: {}\n",
            "      bias_regularizer: null\n",
            "      dtype: float32\n",
            "      kernel_constraint: null\n",
            "      kernel_initializer:\n",
            "        class_name: GlorotUniform\n",
            "        config: {seed: null}\n",
            "      kernel_regularizer: null\n",
            "      name: dense_1\n",
            "      trainable: true\n",
            "      units: 8\n",
            "      use_bias: true\n",
            "  - class_name: Dense\n",
            "    config:\n",
            "      activation: sigmoid\n",
            "      activity_regularizer: null\n",
            "      bias_constraint: null\n",
            "      bias_initializer:\n",
            "        class_name: Zeros\n",
            "        config: {}\n",
            "      bias_regularizer: null\n",
            "      dtype: float32\n",
            "      kernel_constraint: null\n",
            "      kernel_initializer:\n",
            "        class_name: GlorotUniform\n",
            "        config: {seed: null}\n",
            "      kernel_regularizer: null\n",
            "      name: dense_2\n",
            "      trainable: true\n",
            "      units: 1\n",
            "      use_bias: true\n",
            "  name: sequential\n",
            "keras_version: 2.5.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6uuULBISm5V"
      },
      "source": [
        "<a id=\"section4\"></a>\n",
        "# <font color=\"#004D7F\" size=6>4. Guardar topología y pesos</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yli719pRSm5V"
      },
      "source": [
        "Guardar el modelo incluye todo sobre el modelo, que incluye:\n",
        "* Pesos.\n",
        "* Arquitectura.\n",
        "* Detalles de compilación del modelo (pérdidas y métricas).\n",
        "* Estado del optimizador de modelo.\n",
        "\n",
        "Esto significa que podemos cargar y usar el modelo directamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkqomVJVSm5V"
      },
      "source": [
        "<a id=\"section4.1\"></a>\n",
        "# <font color=\"#004D7F\" size=5>4.1. Guardar el modelo</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQBhvGx-Sm5V"
      },
      "source": [
        "La función `save()` guarda el modelo especificando el nombre del archivo. \n",
        "\n",
        "El ejemplo muestra como ajustar un modelo, evaluarlo y guardarlo en el archivo `model.h5`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMMRqXWFSm5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c952b24-bcd0-4add-e096-a24627f62879"
      },
      "source": [
        "# MLP for Pima Indians Dataset saved to single file\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = np.loadtxt(\"https://raw.githubusercontent.com/FMunyoz/colab/main/Datasets/pima-indians-diabetes.csv\", delimiter=',')\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:, 0:8]\n",
        "y = dataset[:, 8]\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 75.13%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owk1-mjGSm5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eec8e6c5-4501-4475-e188-66ba2ca889c6"
      },
      "source": [
        "# save model and architecture to single file\n",
        "model.save(\"model.h5\")\n",
        "print(\"Modelo guardado\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Modelo guardado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKyWgHmzSm5W"
      },
      "source": [
        "<a id=\"section4.2\"></a>\n",
        "# <font color=\"#004D7F\" size=5>4.2. Cargar el modelo</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feGDrUy8Sm5W"
      },
      "source": [
        "Su modelo guardado se puede cargar más tarde llamando a la función `load_model()` y pasando el nombre del archivo. La función devuelve el modelo con la misma arquitectura y pesos. En este caso, cargamos el modelo, resumimos la arquitectura y la evaluamos en el mismo conjunto de datos para confirmar que los pesos y la arquitectura son los mismos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hsZ_YlaoSm5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1e58af-8668-4996-ec07-31ec4fd30752"
      },
      "source": [
        "# load and evaluate a saved model\n",
        "from keras.models import load_model\n",
        "\n",
        "# load model\n",
        "model = load_model('model.h5')\n",
        "\n",
        "# summarize model.\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WWh5KlggSm5X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "399b3908-ad7c-4f21-e6d5-85aae6807cda"
      },
      "source": [
        "# load pima indians dataset\n",
        "dataset = np.loadtxt(\"https://raw.githubusercontent.com/FMunyoz/colab/main/Datasets/pima-indians-diabetes.csv\", delimiter=',')\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:, 0:8]\n",
        "y = dataset[:, 8]\n",
        "\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 75.13%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwU6IVzbSm5X"
      },
      "source": [
        "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
        "\n",
        "---\n",
        "\n",
        "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
      ]
    }
  ]
}