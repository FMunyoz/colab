{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "4. LSTM Clasificación.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q97s9FXNeS31"
      },
      "source": [
        "<h1><font color=\"#113D68\" size=6>Deep Learning con Python y Keras</font></h1>\n",
        "\n",
        "<h1><font color=\"#113D68\" size=5>Parte 6. Redes Neuronales Recurrentes</font></h1>\n",
        "\n",
        "<h1><font color=\"#113D68\" size=4>4. LSTM para Clasificación</font></h1>\n",
        "\n",
        "<br><br>\n",
        "<div style=\"text-align: right\">\n",
        "<font color=\"#113D68\" size=3>Manuel Castillo Cara</font><br>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywbWTEfOeS32"
      },
      "source": [
        "---\n",
        "\n",
        "<a id=\"indice\"></a>\n",
        "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
        "\n",
        "* [0. Contexto](#section0)\n",
        "* [1. LSTM para clasificación](#section1)\n",
        "    * [1.1. Librerías](#section1.1)\n",
        "    * [1.2. Dataset](#section1.2)\n",
        "    * [1.3. Truncar las secuencias de entrada](#section1.3)\n",
        "    * [1.4. Modelo de linea base](#section1.4)\n",
        "    * [1.5. Resultados](#section1.5)\n",
        "* [2. LSTM con Dropout](#section2)\n",
        "* [3. LSTM con Dropout recurrente](#section3)\n",
        "* [4. LSTM y CNN para clasificación](#section4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwM5ZDqheS33"
      },
      "source": [
        "---\n",
        "<a id=\"section0\"></a>\n",
        "# <font color=\"#004D7F\" size=6> 0. Contexto</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awvMCKAfeS33"
      },
      "source": [
        "En este proyecto, vamos a desarrollar modelos LSTM para problemas de clasificación de secuencias:\n",
        "\n",
        "* Desarrollar un modelo LSTM para un problema de clasificación de secuencias.\n",
        "* Reducir el sobreajuste en sus modelos LSTM mediante Dropout.\n",
        "* Combinar modelos LSTM con CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDKK9EgreS33"
      },
      "source": [
        "---\n",
        "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJnxUOGqeS34"
      },
      "source": [
        "<a id=\"section1\"></a>\n",
        "# <font color=\"#004D7F\" size=6>1. LSTM para clasificación</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iimy697SeS34"
      },
      "source": [
        "Para esta práctica vamos a utilizar el problema de clasificación de opiniones de revisión de películas de IMDB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZnrvosieS35"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
        "Puede obtener más información sobre el dataset [IMBD](http://ai.stanford.edu/~amaas/data/sentiment/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb87y-vmeS36"
      },
      "source": [
        "<a id=\"section1.1\"></a>\n",
        "# <font color=\"#004D7F\" size=5>1.1. Funciones</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jNnBq0ueS36"
      },
      "source": [
        "Comencemos importando las clases y funciones necesarias para este modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1FyuMpjeS36"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk7jAZ6MeS37"
      },
      "source": [
        "<a id=\"section1.2\"></a>\n",
        "# <font color=\"#004D7F\" size=5>1.2. Dataset</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUwdM2LheS37"
      },
      "source": [
        "Limitamos el conjunto de datos a las 5.000 palabras principales y dividimos en train (50%) y test (50%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0oImuKGeS37",
        "outputId": "c366aa28-9007-46bd-cec6-7465027a0321"
      },
      "source": [
        "# load the dataset but only keep the top n words, zero the rest\n",
        "max_palabras=5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_palabras)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EycTR2reS38"
      },
      "source": [
        "<a id=\"section1.3\"></a>\n",
        "# <font color=\"#004D7F\" size=5>1.3. Truncar las secuencias de entrada</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R14jlxM6eS38"
      },
      "source": [
        "Necesitamos truncar y rellenar las secuencias de entrada para que todas tengan la misma longitud para el modelado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1oh9LGbeS38"
      },
      "source": [
        "# truncate and pad input sequences\n",
        "max_long = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_long)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_long)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRECdlzheS39"
      },
      "source": [
        "<a id=\"section1.4\"></a>\n",
        "# <font color=\"#004D7F\" size=5>1.4. Modelo de linea base</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmuMto4peS39"
      },
      "source": [
        "Ahora podemos definir nuestro modelo:\n",
        "1. La primera capa es la capa Embedding que utiliza 32 vectores para representar cada palabra. \n",
        "2. La siguiente capa es la capa LSTM con 100 unidades de memoria (neuronas inteligentes). \n",
        "3. Usamos una capa de salida densa con una sola neurona y una función de activación sigmoidea\n",
        "4. Compilamos con `binary_crossentropy`, optimizador `adam` y la métrica Accuracy. \n",
        "5. Ajustamos a 3 épocas y un tamaño de batch=64."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lfpsAY5eS39",
        "outputId": "6779da98-ea7a-4df7-8c99-ba950f78d17f"
      },
      "source": [
        "# create the model\n",
        "embedding_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_palabras, embedding_length , input_length = max_long))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "model.fit(X_train, y_train, epochs=3, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "391/391 [==============================] - 31s 27ms/step - loss: 0.6009 - accuracy: 0.6513\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.3346 - accuracy: 0.8631\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.2693 - accuracy: 0.8946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa37ac5b810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqq7dKY5eS3-"
      },
      "source": [
        "<a id=\"section1.5\"></a>\n",
        "# <font color=\"#004D7F\" size=5>1.5. Resultados</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR-jpG_3eS3-"
      },
      "source": [
        "Estimamos el rendimiento del modelo en revisiones no vistas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMezhsFXeS3-",
        "outputId": "e91152d0-2a0e-4e1c-bcb1-71454384a803"
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 87.45%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNgXbC8oeS3-"
      },
      "source": [
        "---\n",
        "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7kv-DdreS3-"
      },
      "source": [
        "<a id=\"section2\"></a>\n",
        "# <font color=\"#004D7F\" size=6>2. LSTM con Dropout</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqSxrxJEeS3_"
      },
      "source": [
        "Podemos regular el problema de sobreajuste en RNN agregando nuevas capas Dropout entre las capas Embedding y LSTM y las capas de salida LSTM y Dense."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yf3a6bbeS3_",
        "outputId": "5e8b9405-58ba-462b-d567-8d4425b40f29"
      },
      "source": [
        "# create the model\n",
        "embedding_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_palabras, embedding_length , input_length = max_long))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64)\n",
        "\n",
        "#evaluate model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "391/391 [==============================] - 12s 27ms/step - loss: 0.6111 - accuracy: 0.6540\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.3578 - accuracy: 0.8538\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2963 - accuracy: 0.8798\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2588 - accuracy: 0.9013\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2455 - accuracy: 0.9085\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.2054 - accuracy: 0.9267\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1794 - accuracy: 0.9351\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1574 - accuracy: 0.9414\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1422 - accuracy: 0.9493\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.1439 - accuracy: 0.9481\n",
            "Accuracy: 83.32%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbpKjryFeS3_"
      },
      "source": [
        "---\n",
        "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AILNHm-seS3_"
      },
      "source": [
        "<a id=\"section3\"></a>\n",
        "# <font color=\"#004D7F\" size=6>3. LSTM con Dropout recurrente</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aFJiFAYeS3_"
      },
      "source": [
        "Alternativamente, Dropout se puede aplicar a las conexiones de entrada y recurrentes de las unidades de memoria con el LSTM de manera precisa y por separado. Para ello, configuraremos el `dropout` de entrada y `recurrent_dropout` para configurar el Dropout recurrente. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGGx2iqIeS3_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "141bb517-d0c9-4cd6-ccfb-bffdef8ba2e9"
      },
      "source": [
        "# create the model\n",
        "embedding_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_palabras, embedding_length , input_length = max_long))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "\n",
        "#evaluate model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            " 28/391 [=>............................] - ETA: 10:52 - loss: 0.6933 - accuracy: 0.4842"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f8f1738c9fe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MprR031GeS3_"
      },
      "source": [
        "---\n",
        "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPgKGzTYeS3_"
      },
      "source": [
        "<a id=\"section4\"></a>\n",
        "# <font color=\"#004D7F\" size=6>4. LSTM y CNN para clasificación</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zChHiyhueS4A"
      },
      "source": [
        "Podemos agregar fácilmente una CNN unidimensional y capas de agrupación máxima después de la capa Embedding que luego alimentan las características consolidadas al LSTM.\n",
        "\n",
        "Utilizaremos:\n",
        "1. En la convolución un conjunto más pequeño de 32 entidades con un filtro de 3. \n",
        "2. La capa de agrupación la longitud estándar de 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYQvXiK2eS4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6841fa0c-a792-4646-8980-775854510bfa"
      },
      "source": [
        "# libraries\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "\n",
        "# create the model\n",
        "embedding_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_palabras, embedding_length , input_length = max_long))\n",
        "model.add(Conv1D(32, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "\n",
        "#evaluate model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# Final evaluation of the model\n",
        "???"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 500, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 250, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 216,405\n",
            "Trainable params: 216,405\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "391/391 [==============================] - 75s 21ms/step - loss: 0.5557 - accuracy: 0.6869\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 8s 21ms/step - loss: 0.2401 - accuracy: 0.9067\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.1831 - accuracy: 0.9354\n",
            "Accuracy: 87.51%\n",
            "Object `` not found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf_vtGUIeS4A"
      },
      "source": [
        "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
        "\n",
        "---\n",
        "\n",
        "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
      ]
    }
  ]
}