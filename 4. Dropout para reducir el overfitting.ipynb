{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "4. Dropout para reducir el overfitting.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RaBmh38Lby1"
      },
      "source": [
        "<h1><font color=\"#113D68\" size=6>Deep Learning con Python y Keras</font></h1>\n",
        "\n",
        "<h1><font color=\"#113D68\" size=5>Parte 4. MLP avanzado</font></h1>\n",
        "\n",
        "<h1><font color=\"#113D68\" size=4>4. Dropout para reducir el overfitting</font></h1>\n",
        "\n",
        "<br><br>\n",
        "<div style=\"text-align: right\">\n",
        "<font color=\"#113D68\" size=3>Manuel Castillo Cara</font><br>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVcJcgKHLby2"
      },
      "source": [
        "---\n",
        "\n",
        "<a id=\"indice\"></a>\n",
        "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
        "\n",
        "* [0. Contexto](#section0)\n",
        "* [1. Introducción](#section1)\n",
        "* [2. Regularización por dropout](#section2)\n",
        "* [3. Dropout en la capa visible](#section3)\n",
        "* [4. Dropout en capas ocultas](#section4)\n",
        "* [5. Consejos al utilizar Dropout](#section5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWhebdohLby2"
      },
      "source": [
        "---\n",
        "<a id=\"section0\"></a>\n",
        "# <font color=\"#004D7F\" size=6> 0. Contexto</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOEd3YN7Lby2"
      },
      "source": [
        "En esta lección, descubrirá la técnica de regularización de _Dropout_ y cómo aplicarla. Después de completar esta lección, sabrá:\n",
        "* Cómo funciona la técnica de regularización de _Dropout._\n",
        "* Cómo utilizar _Dropout_ en sus capas de entrada.\n",
        "* Cómo utilizar _Dropout_ en sus capas ocultas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPtuaG-3Lby2"
      },
      "source": [
        "import tensorflow as tf\n",
        "# Eliminar warning\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ-TSngALby2"
      },
      "source": [
        "---\n",
        "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjW72Sa_Lby3"
      },
      "source": [
        "<a id=\"section1\"></a>\n",
        "# <font color=\"#004D7F\" size=6>1. Introducción</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVSTQ3FALby3"
      },
      "source": [
        "Dropout es una técnica en la que se ignoran las neuronas seleccionadas al azar durante el entrenamiento. Se eliminan al azar. Esto significa que su contribución a la activación de las neuronas siguientes se elimina temporalmente en el pase hacia adelante y las actualizaciones de peso no se aplican a la neurona en el pase hacia atrás.\n",
        "\n",
        "Esta dependencia del contexto de una neurona durante el entrenamiento se denomina _coadaptaciones complejas._ Entonces si las neuronas se eliminan aleatoriamente, otras neuronas tendrán que intervenir y manejar la representación requerida para hacer predicciones para las neuronas faltantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEjdPp6gLby3"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
        "Más información sobre el artículo [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://jmlr.org/papers/v15/srivastava14a.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDcNUFeoLby3"
      },
      "source": [
        "---\n",
        "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQCqvh4dLby3"
      },
      "source": [
        "<a id=\"section2\"></a>\n",
        "# <font color=\"#004D7F\" size=6>2. Regularización por Dropout</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia2KEdSOLby3"
      },
      "source": [
        "_Dropout_ se implementa fácilmente seleccionando aleatoriamente los nodos que se eliminarán con una probabilidad determinada (por ejemplo, 20%) en cada ciclo de actualización de peso.\n",
        "\n",
        "Los ejemplos utilizarán el conjunto de datos de clasificación binaria del conjunto de datos de Sonar. \n",
        "\n",
        "El modelo de red neuronal de línea de base tiene:\n",
        "1. Dos capas ocultas, la primera con 60 neuronas y la segunda con 30. \n",
        "2. Gradiente Descendiente Estocástico se utiliza para el entrenamiento con una tasa de aprendizaje y _momentum_ relativamente bajos. \n",
        "\n",
        "Veamos los resultados de linea base sin _Dropout._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N5eAVfDLby3",
        "outputId": "b2ae02cb-a9fd-40fb-8f5b-7877b008fe60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Baseline Model on the Sonar Dataset\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# load dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/FMunyoz/colab/main/Datasets/sonar.csv', header=None)\n",
        "df_values = df.values\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = df_values[:, 0:60]\n",
        "y = df_values[:, 60]\n",
        "\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "encoded_y = encoder.transform(y)\n",
        "\n",
        "# baseline\n",
        "def baseline_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(60, input_dim=60, activation='relu'))\n",
        "  model.add(Dense(30, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  sgd = SGD(lr=0.01, momentum=0.8)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "  return model\n",
        "# Results\n",
        "estimator = []\n",
        "estimator.append(('standarize', StandardScaler()))\n",
        "estimator.append(('MLP', KerasClassifier(build_fn=baseline_model, epochs=300, batch_size=16, verbose=0)))\n",
        "\n",
        "pipeline = Pipeline(estimator)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "\n",
        "results = cross_val_score(pipeline, X, encoded_y, cv=kfold)\n",
        "print(\" Modelo de linea base: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3dcdd2b5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3dcd77e8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Modelo de linea base: 88.45% (4.89%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysPEb1oGLby4"
      },
      "source": [
        "---\n",
        "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcovnOLpLby4"
      },
      "source": [
        "<a id=\"section3\"></a>\n",
        "# <font color=\"#004D7F\" size=6>3. Dropout en la capa visible</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sNF2M2kLby4"
      },
      "source": [
        "_Dropout_ se puede aplicar a las neuronas de entrada. En el siguiente ejemplo: \n",
        "\n",
        "1. Agregamos una nueva capa de exclusión entre la entrada (o capa visible) y la primera capa oculta. \n",
        "2. La tasa de _Dropout_ se establece en 20%, i.e., una de cada cinco entradas se excluirá al azar.\n",
        "3. Se impone una restricción en los pesos para cada capa oculta con la norma máxima de los pesos para que no exceda de 3. \n",
        "    * Esto se hace estableciendo el argumento de `kernel_constraint` en el clase `Dense` al construir las capas. \n",
        "4. Aumentamos la tasa de aprendizaje y momentum. \n",
        "\n",
        "Vemoas el código"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLaarFPtLby4",
        "outputId": "8cb993f5-37d3-43b6-f60a-494b0fb72de4"
      },
      "source": [
        "# Example of Dropout on the Sonar Dataset: Visible Layer\n",
        "???\n",
        "\n",
        "# load dataset\n",
        "???\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "???\n",
        "\n",
        "# encode class values as integers\n",
        "???\n",
        "\n",
        "# dropout in the input layer with weight constraint\n",
        "???\n",
        "\n",
        "#Results\n",
        "???\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Visible: 86.57% (8.45%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C7ImaTSLby4"
      },
      "source": [
        "<a id=\"section4\"></a>\n",
        "# <font color=\"#004D7F\" size=6>4. Dropout en capas ocultas</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlgEL4aZLby5"
      },
      "source": [
        "_Dropout_ se aplica también a las capas ocultas. En el siguiente ejemplo:\n",
        "\n",
        "1. _Dropout_ se aplica entre las dos capas ocultas y entre la última capa oculta y la capa de salida. \n",
        "2. Nuevamente, se usa una tasa de _Dropout_ del 20%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTyNHX4iLby5",
        "outputId": "813667fc-e754-46eb-ee90-3fd002199d34"
      },
      "source": [
        "# Example of Dropout on the Sonar Dataset: Hidden Layer\n",
        "???\n",
        "\n",
        "# load dataset\n",
        "???\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "???\n",
        "\n",
        "# encode class values as integers\n",
        "???\n",
        "\n",
        "# dropout in hidden layers with weight constraint\n",
        "???\n",
        "\n",
        "# Results\n",
        "???\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hidden: 84.14% (5.63%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG2ufPzQLby5"
      },
      "source": [
        "<a id=\"section5\"></a>\n",
        "# <font color=\"#004D7F\" size=6>5. Consejos al utilizar Dropout</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHJLkCovLby5"
      },
      "source": [
        "El documento original sobre _Dropout_ proporciona resultados experimentales sobre un conjunto de problemas estándar de Machine Learning. Como resultado, proporcionan una serie de heurísticas útiles a considerar cuando se usa la deserción en la práctica:\n",
        "* Por lo general, utilice un pequeño valor de _Dropout_ del 20% al 20%-50% como punto de partida.\n",
        "* Utilizar una red más grande.\n",
        "* Utilizar _Dropout_ en la entrada (capa visible) y capas ocultas. \n",
        "* Utilizar una gran tasa de aprendizaje y un gran momentum. \n",
        "* Restrinja el tamaño de los pesos de la red. Una gran tasa de aprendizaje puede resultar en pesos de red muy grandes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W6cxX4sLby5"
      },
      "source": [
        "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
        "\n",
        "---\n",
        "\n",
        "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
      ]
    }
  ]
}